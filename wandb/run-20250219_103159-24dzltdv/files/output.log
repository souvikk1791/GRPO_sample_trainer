Loading model ..
get peft model
Creating reference model
start training
GRPO Training:   0%|                                                                                                                                   | 0/4680 [00:00<?, ?it/s]Traceback (most recent call last):
<|im_start|>system

You are an helpful Assistant with excellent reasoning ability. When the user asks the question and the assistant solves the problem by reasoning in a step by step manner in 'English` Â¯and then provides the user
with the answer. Always respond in 'English` in the following format:
<reasoning> {your step by step reasoning process here} </reasoning>
<answer> {answer here} </answer>
<|im_end|>
<|im_start|>user
At peak hours, 11 am - 1 pm and 5 pm - 6 pm, the local fast-food restaurant serves 12 cars every 15 minutes.  Off-peak times, they serve 8 cars every 15 minutes.  From 4 pm - 6 pm, how many customers do they serve?<|im_end|>
<|im_start|>assistant

running inference
running inference
input_shape torch.Size([32, 2048])
mask.device cuda:0
final_advantages.device cuda:0
per_token_loss.size torch.Size([4, 2047])
loss from sum: tensor([0., 0., 0., 0.], device='cuda:0', grad_fn=<DivBackward0>)
  File "/home/jovyan/data/vision training/GRPO_sample_trainer/trainer.py", line 102, in <module>
    trainer.train(dataloader, save_directory="models/")
  File "/home/jovyan/data/vision training/GRPO_sample_trainer/grpo.py", line 410, in train
    logp_proxy = self.logp_per_token(self.model, current_inputs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/GRPO_sample_trainer/grpo.py", line 248, in logp_per_token
    return self.selective_log_softmax(logits.float(), input_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/GRPO_sample_trainer/grpo.py", line 230, in selective_log_softmax
    logsumexp_values = torch.stack([torch.logsumexp(lg, dim=-1) for lg in logits])
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1015, please report a bug to PyTorch.
