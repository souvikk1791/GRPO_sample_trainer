Loading model ..
get peft model
Creating reference model
start training
GRPO Training:   0%|                                                           | 1/4680 [01:12<94:43:35, 72.88s/it, rewards=-0.0118, loss=-0.00505, kl_div=0, objective=0.00505]
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0., device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0., device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1577, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0., device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1981, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0., device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0., device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0., device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0078, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1909, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0089, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1731, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0046, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0036, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0054, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0093, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0125, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0125, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0281, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0229, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1197, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0216, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0325, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0085, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0066, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0066, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0133, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0178, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.2657, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0090, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0130, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0049, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0093, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0107, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0048, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0074, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0060, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0080, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0094, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0158, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0143, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0113, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0082, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0103, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0121, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0155, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0086, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0124, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0103, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0087, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0094, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0151, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0092, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0092, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0061, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0131, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0089, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0090, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0159, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0035, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0065, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0060, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0089, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0062, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0078, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0063, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0060, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0058, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0081, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0083, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0080, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0099, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0086, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0099, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0103, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0066, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0091, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0093, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0085, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0078, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0080, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0063, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0091, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0091, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0072, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0105, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0114, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0099, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0143, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0234, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0134, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0096, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0096, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0093, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0080, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0107, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0107, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0178, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0121, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0084, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0087, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0082, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0099, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0062, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0046, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0072, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0153, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0071, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0082, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0057, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0072, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0085, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0145, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0082, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0108, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0077, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0123, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0093, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0079, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0085, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0129, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0065, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0077, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0101, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0098, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0095, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0078, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0065, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.5070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1435, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0064, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0057, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.5152, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0050, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0068, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1600, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0071, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0063, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0117, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0084, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0071, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0049, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0077, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0122, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0121, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0084, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0076, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0064, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0074, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0084, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0063, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0079, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0058, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0050, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0106, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0081, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0086, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0043, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0054, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0101, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0078, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0075, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0067, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0100, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0042, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0067, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0078, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0077, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0081, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0103, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0040, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0075, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0087, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0121, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0129, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0101, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0097, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0065, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0129, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0088, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0088, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0090, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0094, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0057, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0088, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0061, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0092, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0072, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0079, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0043, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0075, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0058, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0090, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0039, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0050, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0056, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0078, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0036, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0054, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0038, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0050, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0074, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0091, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0079, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0327, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0043, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0071, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0086, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0060, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0072, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0554, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0061, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0089, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0062, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0046, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0840, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0071, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0088, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0045, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0055, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0047, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0050, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1026, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0070, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0041, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0066, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0081, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0076, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.3013, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0058, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0039, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0084, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.3143, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0085, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.2839, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0041, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0058, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0066, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0057, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0085, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0061, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0054, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.3352, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0055, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0063, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0093, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0073, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0114, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0057, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0049, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.3270, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0045, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0066, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0133, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0098, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0034, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0058, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0048, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.3221, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0039, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0130, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0088, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0037, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0050, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0063, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0103, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0358, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0150, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0043, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2514, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0055, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0097, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0130, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0081, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0068, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0060, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2338, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0033, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0092, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0042, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0052, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0049, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0046, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0068, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0030, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0086, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0038, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0046, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0045, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1061, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1245, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0081, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0059, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0038, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0065, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0041, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0042, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0860, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1342, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0072, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0053, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0044, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0061, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0035, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0064, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2961, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0187, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.2519, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2410, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.6820, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0099, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0187, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0079, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2764, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0092, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.2970, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2319, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.6353, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0151, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0244, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0030, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0031, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1598, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0120, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1813, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.6642, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0039, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0715, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0054, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0040, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1800, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0152, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1074, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.6841, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0069, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1015, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.6154, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0698, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0061, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0067, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.4849, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0082, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.4430, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0105, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.6023, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0794, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0089, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0064, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.4672, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0106, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.4283, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0097, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0055, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.6016, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.3141, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1133, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1192, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0811, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.9237, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.4760, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0051, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.5708, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.3658, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1140, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1450, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1051, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.8493, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.4413, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.3047, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0682, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.5709, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0128, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.8656, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2453, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1290, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0067, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.4365, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0142, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.5722, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0046, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.8906, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1731, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1692, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0079, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0035, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.3230, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.3609, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0770, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0007, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1925, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.5898, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1299, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0275, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2855, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.2759, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.0512, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.1325, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.2711, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.6428, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.1050, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.7748, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.9453, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(1.4367, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0105, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0199, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.4344, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0131, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.6387, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(-0.7201, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(1.0783, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(1.6085, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0108, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0169, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.4872, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.0123, device='cuda:0', grad_fn=<SumBackward0>)
per_token_loss.size torch.Size([4, 1023])
loss from sum: tensor(0.7159, device='cuda:0', grad_fn=<SumBackward0>)
running inference
running inference
input_shape torch.Size([32, 1024])
  File "/home/jovyan/data/vision training/GRPO_sample_trainer/trainer.py", line 102, in <module>
    trainer.train(dataloader, save_directory="models/")
  File "/home/jovyan/data/vision training/GRPO_sample_trainer/grpo.py", line 376, in train
    logp_refs = self.logp_per_token(self.reference_model, current_inputs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/GRPO_sample_trainer/grpo.py", line 235, in logp_per_token
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/peft/peft_model.py", line 1719, in forward
    return self.base_model(
           ^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 819, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 577, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
    hidden_states, self_attn_weights = self.self_attn(
                                       ^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 191, in forward
    attn_output, attn_weights = attention_interface(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/home/jovyan/data/vision training/py3.12/lib/python3.12/site-packages/transformers/integrations/flash_attention.py", line 28, in flash_attention_forward
    query = query.transpose(1, 2)
            ^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
